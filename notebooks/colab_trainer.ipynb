{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "initial_id",
    "outputId": "bd753265-43f5-4386-997c-979cfcd0f3dd"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'master'...\n",
      "remote: Enumerating objects: 118, done.\u001B[K\n",
      "remote: Counting objects: 100% (118/118), done.\u001B[K\n",
      "remote: Compressing objects: 100% (102/102), done.\u001B[K\n",
      "remote: Total 118 (delta 17), reused 105 (delta 4), pack-reused 0 (from 0)\u001B[K\n",
      "Receiving objects: 100% (118/118), 948.38 KiB | 27.89 MiB/s, done.\n",
      "Resolving deltas: 100% (17/17), done.\n",
      "Filtering content: 100% (6/6), 962.13 MiB | 41.50 MiB/s, done.\n",
      "\u001B[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: './content/master/requirements.txt'\u001B[0m\u001B[31m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if \"master\" not in os.listdir(\"./\"):\n",
    "  !git clone https://github.com/YounesHB92/master.git\n",
    "  !pip install -r ./master/requirements.txt\n",
    "else:\n",
    "  print(\"Already cloned!\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "if \"/content/master\" not in sys.path:\n",
    "  sys.path.append('/content/master')\n",
    "else:\n",
    "  print(\"Already added!\")"
   ],
   "metadata": {
    "id": "aj2F8gsfbEZH"
   },
   "id": "aj2F8gsfbEZH",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if \"datasets.tar.gz\" not in os.listdir(\"./\"):\n",
    "  !gdown \"https://drive.google.com/uc?id=1Gtw4q4pkMHWMYz5urew5C44X17oLE9e3\"\n",
    "  !tar -xvf datasets.tar.gz -C ./master\n",
    "else:\n",
    "  print(\"Already downloaded!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdeWEiFIbRet",
    "outputId": "4f51db41-be53-4e81-e2f3-e3291ba03146"
   },
   "id": "RdeWEiFIbRet",
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Already downloaded!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from src.datasets import DatasetIterator\n",
    "from src.training import Trainer\n",
    "from src.models import LoadModel\n",
    "from src.utils import Optimizer"
   ],
   "metadata": {
    "id": "wk5-Jgulbuoa"
   },
   "id": "wk5-Jgulbuoa",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "encoders = [\n",
    "    \"tu-mvitv2_base\",\n",
    "    \"swin_base_patch4_window7_224\",\n",
    "    \"convnext_base\"\n",
    "]\n",
    "\n",
    "main_device = \"colab\" if \"google.colab\" in str(get_ipython()) else \"local\"\n",
    "output_path = \"/content/drive/MyDrive/train_outputs\" if main_device == \"colab\" else \"./experiments/outputs\"\n",
    "datasets_base_path = \"./master/datasets\" if main_device == \"colab\" else \"./datasets\"\n",
    "\n",
    "for encoder_name in encoders:\n",
    "    dataset_loader_ = DatasetIterator(\n",
    "        train_path=os.path.join(datasets_base_path, \"splits/masks/train\"),\n",
    "        val_path=os.path.join(datasets_base_path, \"splits/masks/val\"),\n",
    "        batch_size=4,\n",
    "        augment=True\n",
    "    )\n",
    "    model_ = LoadModel(\n",
    "        encoder=encoder_name,\n",
    "        num_classes=dataset_loader_.num_classes\n",
    "    )\n",
    "    optimizer_ = Optimizer(\n",
    "        model=model_.model\n",
    "    )\n",
    "\n",
    "    trainer_ = Trainer(\n",
    "        model=model_.model,\n",
    "        train_loader=dataset_loader_.train_loader,\n",
    "        val_loader=dataset_loader_.val_loader,\n",
    "        loss_function=optimizer_.loss_function,\n",
    "        optimizer=optimizer_.optimizer,\n",
    "        scheduler=optimizer_.scheduler,\n",
    "        device=\"cuda\",\n",
    "        output_dir=output_path,\n",
    "        num_epochs=2,\n",
    "        details=\"test in local computer where augmentation is applied\",\n",
    "        augment=dataset_loader_.augment\n",
    "    ).run_training()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5151c844c1f54cb7b3d432e3004d8c6d",
      "637a3c89bf1c4c759af9ff319a5b2379",
      "a82d875eb4f5440d80f63b90cf5e35ac",
      "7bbb2446c82d417c8de1dd6c1a09c896",
      "d6fb4db9eb65401288fa3f0926135eed",
      "9f8e959b4ef84cd69b9c7fd8f6d9e287",
      "f8dfd7ca11d747f4ae4d9489638ba8f3",
      "f6b23433e1544275b7bc609fff8b998a",
      "45b8e3fe8a2340d9ad284507cfeb02d7",
      "1d30018f605d450e9768e0cbf85f6db5",
      "77fee0fe72ab4674ac25eeed7691cbbd"
     ]
    },
    "id": "bt1pilaahfwE",
    "outputId": "8fcfa8da-a1f9-4975-e327-fbc8a6b8e761"
   },
   "id": "bt1pilaahfwE",
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Datasets are ready!\n",
      "\tDetected 7 classes: \n",
      "\t\tb\n",
      "l\n",
      "o\n",
      "c\n",
      "k\n",
      "\t\n",
      "c\n",
      "r\n",
      "e\n",
      "s\n",
      "c\n",
      "e\n",
      "n\n",
      "t\n",
      "\t\n",
      "c\n",
      "r\n",
      "o\n",
      "c\n",
      "o\n",
      "d\n",
      "i\n",
      "l\n",
      "e\n",
      "\t\n",
      "d\n",
      "i\n",
      "a\n",
      "g\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      "\t\n",
      "l\n",
      "o\n",
      "n\n",
      "g\n",
      "i\n",
      "t\n",
      "u\n",
      "d\n",
      "i\n",
      "n\n",
      "a\n",
      "l\n",
      "\t\n",
      "m\n",
      "e\n",
      "a\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      "\t\n",
      "t\n",
      "r\n",
      "a\n",
      "n\n",
      "s\n",
      "v\n",
      "e\n",
      "r\n",
      "s\n",
      "e\n",
      "datasets_.train_loader and datasets_.val_loader to be used!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/206M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5151c844c1f54cb7b3d432e3004d8c6d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ClassificationHead(\n",
      "  (encoder): TimmUniversalEncoder(\n",
      "    (model): FeatureGetterNet(\n",
      "      (model): MultiScaleVit(\n",
      "        (patch_embed): PatchEmbed(\n",
      "          (proj): Conv2d(3, 96, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
      "        )\n",
      "        (stages): ModuleList(\n",
      "          (0): MultiScaleVitStage(\n",
      "            (blocks): ModuleList(\n",
      "              (0-1): 2 x MultiScaleBlock(\n",
      "                (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                (attn): MultiScaleAttention(\n",
      "                  (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "                  (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                  (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                  (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                )\n",
      "                (drop_path1): Identity()\n",
      "                (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): Identity()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): MultiScaleVitStage(\n",
      "            (blocks): ModuleList(\n",
      "              (0): MultiScaleBlock(\n",
      "                (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                (shortcut_proj_attn): Linear(in_features=96, out_features=192, bias=True)\n",
      "                (shortcut_pool_attn): MaxPool2d(kernel_size=[3, 3], stride=(2, 2), padding=[1, 1], dilation=1, ceil_mode=False)\n",
      "                (attn): MultiScaleAttention(\n",
      "                  (qkv): Linear(in_features=96, out_features=576, bias=True)\n",
      "                  (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                  (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                  (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                )\n",
      "                (drop_path1): Identity()\n",
      "                (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): Identity()\n",
      "              )\n",
      "              (1-2): 2 x MultiScaleBlock(\n",
      "                (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "                (attn): MultiScaleAttention(\n",
      "                  (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "                  (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                  (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                  (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                )\n",
      "                (drop_path1): Identity()\n",
      "                (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): Identity()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): MultiScaleVitStage(\n",
      "            (blocks): ModuleList(\n",
      "              (0): MultiScaleBlock(\n",
      "                (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "                (shortcut_proj_attn): Linear(in_features=192, out_features=384, bias=True)\n",
      "                (shortcut_pool_attn): MaxPool2d(kernel_size=[3, 3], stride=(2, 2), padding=[1, 1], dilation=1, ceil_mode=False)\n",
      "                (attn): MultiScaleAttention(\n",
      "                  (qkv): Linear(in_features=192, out_features=1152, bias=True)\n",
      "                  (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                  (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                  (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                )\n",
      "                (drop_path1): Identity()\n",
      "                (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): Identity()\n",
      "              )\n",
      "              (1-15): 15 x MultiScaleBlock(\n",
      "                (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (attn): MultiScaleAttention(\n",
      "                  (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                  (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                  (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                  (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                )\n",
      "                (drop_path1): Identity()\n",
      "                (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): Identity()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): MultiScaleVitStage(\n",
      "            (blocks): ModuleList(\n",
      "              (0): MultiScaleBlock(\n",
      "                (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (shortcut_proj_attn): Linear(in_features=384, out_features=768, bias=True)\n",
      "                (shortcut_pool_attn): MaxPool2d(kernel_size=[3, 3], stride=(2, 2), padding=[1, 1], dilation=1, ceil_mode=False)\n",
      "                (attn): MultiScaleAttention(\n",
      "                  (qkv): Linear(in_features=384, out_features=2304, bias=True)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                  (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                  (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                )\n",
      "                (drop_path1): Identity()\n",
      "                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): Identity()\n",
      "              )\n",
      "              (1-2): 2 x MultiScaleBlock(\n",
      "                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "                (attn): MultiScaleAttention(\n",
      "                  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                  (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                  (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                )\n",
      "                (drop_path1): Identity()\n",
      "                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): Identity()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (norm): Identity()\n",
      "        (head): Sequential(\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "          (fc): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooling): AdaptiveAvgPool2d(output_size=1)\n",
      "  (fc): Linear(in_features=768, out_features=7, bias=True)\n",
      ")\n",
      "\n",
      "Model is ready!\n",
      "\t model_.model to be used!\n",
      "Loss function, Optimizer and Scheduler are ready!\n",
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/175 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-950e8b789eda>\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     36\u001B[0m         \u001B[0mdetails\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"test in local computer where augmentation is applied\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m         \u001B[0maugment\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdataset_loader_\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maugment\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 38\u001B[0;31m     ).run_training()\n\u001B[0m",
      "\u001B[0;32m/content/master/src/training/trainer.py\u001B[0m in \u001B[0;36mrun_training\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     45\u001B[0m             \u001B[0mtrain_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcorrect\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtotal\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mimages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 47\u001B[0;31m                 \u001B[0mimages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimages\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     48\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001B[0m in \u001B[0;36m_lazy_init\u001B[0;34m()\u001B[0m\n\u001B[1;32m    317\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;34m\"CUDA_MODULE_LOADING\"\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menviron\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    318\u001B[0m             \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menviron\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"CUDA_MODULE_LOADING\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"LAZY\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 319\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_cuda_init\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    320\u001B[0m         \u001B[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    321\u001B[0m         \u001B[0;31m# we need to just return without initializing in that case.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "6JM-1-NfibBq"
   },
   "id": "6JM-1-NfibBq",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "5151c844c1f54cb7b3d432e3004d8c6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_637a3c89bf1c4c759af9ff319a5b2379",
       "IPY_MODEL_a82d875eb4f5440d80f63b90cf5e35ac",
       "IPY_MODEL_7bbb2446c82d417c8de1dd6c1a09c896"
      ],
      "layout": "IPY_MODEL_d6fb4db9eb65401288fa3f0926135eed"
     }
    },
    "637a3c89bf1c4c759af9ff319a5b2379": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f8e959b4ef84cd69b9c7fd8f6d9e287",
      "placeholder": "​",
      "style": "IPY_MODEL_f8dfd7ca11d747f4ae4d9489638ba8f3",
      "value": "model.safetensors: 100%"
     }
    },
    "a82d875eb4f5440d80f63b90cf5e35ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6b23433e1544275b7bc609fff8b998a",
      "max": 205948668,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_45b8e3fe8a2340d9ad284507cfeb02d7",
      "value": 205948668
     }
    },
    "7bbb2446c82d417c8de1dd6c1a09c896": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d30018f605d450e9768e0cbf85f6db5",
      "placeholder": "​",
      "style": "IPY_MODEL_77fee0fe72ab4674ac25eeed7691cbbd",
      "value": " 206M/206M [00:01&lt;00:00, 212MB/s]"
     }
    },
    "d6fb4db9eb65401288fa3f0926135eed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f8e959b4ef84cd69b9c7fd8f6d9e287": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8dfd7ca11d747f4ae4d9489638ba8f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6b23433e1544275b7bc609fff8b998a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45b8e3fe8a2340d9ad284507cfeb02d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1d30018f605d450e9768e0cbf85f6db5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77fee0fe72ab4674ac25eeed7691cbbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
